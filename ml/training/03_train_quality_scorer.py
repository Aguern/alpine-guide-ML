#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TourismIQ - EntraÃ®nement Quality Scorer

EntraÃ®ne un modÃ¨le LightGBM pour prÃ©dire le quality_score (0-100)

Objectifs:
- RÂ² > 0.75
- MAE < 10 points
- RMSE < 12 points
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import GradientBoostingRegressor

print("=" * 80)
print("ğŸ¤– TOURISMIQ - ENTRAÃNEMENT QUALITY SCORER")
print("=" * 80)

# ============================================================================
# 1. CHARGEMENT DES DONNÃ‰ES
# ============================================================================
print("\nğŸ“‚ 1. CHARGEMENT DES DONNÃ‰ES")
print("-" * 80)

data_file = Path("../data/processed/features_ml.parquet")
df = pd.read_parquet(data_file)

print(f"âœ… {len(df):,} POIs chargÃ©s")
print(f"   Features: {len(df.columns) - 1}")
print(f"   Target: quality_score")

# Statistiques target
print(f"\nğŸ“Š Statistiques target (quality_score):")
print(f"   Moyenne: {df['quality_score'].mean():.1f}")
print(f"   MÃ©diane: {df['quality_score'].median():.1f}")
print(f"   Ã‰cart-type: {df['quality_score'].std():.1f}")
print(f"   Min: {df['quality_score'].min():.1f}, Max: {df['quality_score'].max():.1f}")

# ============================================================================
# 2. PRÃ‰PARATION DONNÃ‰ES ML
# ============================================================================
print("\n\nâš™ï¸  2. PRÃ‰PARATION DONNÃ‰ES ML")
print("-" * 80)

# Features Ã  utiliser (exclure IDs et target)
feature_cols = [col for col in df.columns if col not in [
    'uuid', 'name', 'type', 'quality_score'
]]

print(f"Features sÃ©lectionnÃ©es ({len(feature_cols)}):")
for i, col in enumerate(feature_cols, 1):
    print(f"  {i:2d}. {col}")

# PrÃ©parer X et y
X = df[feature_cols].copy()
y = df['quality_score'].copy()

# GÃ©rer valeurs manquantes (remplacer par 0)
X = X.fillna(0)

print(f"\nâœ… X shape: {X.shape}")
print(f"âœ… y shape: {y.shape}")

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nğŸ“Š Split:")
print(f"   Train: {len(X_train):,} POIs ({len(X_train)/len(X)*100:.1f}%)")
print(f"   Test:  {len(X_test):,} POIs ({len(X_test)/len(X)*100:.1f}%)")

# ============================================================================
# 3. ENTRAÃNEMENT GRADIENT BOOSTING (scikit-learn)
# ============================================================================
print("\n\nğŸš€ 3. ENTRAÃNEMENT GRADIENT BOOSTING")
print("-" * 80)

# ParamÃ¨tres Gradient Boosting
params = {
    'n_estimators': 200,
    'learning_rate': 0.1,
    'max_depth': 5,
    'min_samples_split': 20,
    'min_samples_leaf': 15,
    'subsample': 0.8,
    'random_state': 42,
    'verbose': 1
}

print("ParamÃ¨tres:")
for key, val in params.items():
    print(f"  â€¢ {key}: {val}")

print("\nğŸ”„ EntraÃ®nement en cours...")

# CrÃ©er et entraÃ®ner le modÃ¨le
model = GradientBoostingRegressor(**params)
model.fit(X_train, y_train)

print(f"\nâœ… EntraÃ®nement terminÃ©")
print(f"   N estimators: {model.n_estimators}")
print(f"   Train score: {model.score(X_train, y_train):.4f}")

# ============================================================================
# 4. Ã‰VALUATION
# ============================================================================
print("\n\nğŸ“Š 4. Ã‰VALUATION DU MODÃˆLE")
print("-" * 80)

# PrÃ©dictions
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# MÃ©triques train
train_mae = mean_absolute_error(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
train_r2 = r2_score(y_train, y_train_pred)

# MÃ©triques test
test_mae = mean_absolute_error(y_test, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_r2 = r2_score(y_test, y_test_pred)

print("Performances Train:")
print(f"  â€¢ MAE:  {train_mae:.2f} points")
print(f"  â€¢ RMSE: {train_rmse:.2f} points")
print(f"  â€¢ RÂ²:   {train_r2:.4f}")

print("\nPerformances Test:")
print(f"  â€¢ MAE:  {test_mae:.2f} points")
print(f"  â€¢ RMSE: {test_rmse:.2f} points")
print(f"  â€¢ RÂ²:   {test_r2:.4f}")

# VÃ©rifier objectifs
print("\nğŸ¯ Objectifs:")
status_r2 = "âœ…" if test_r2 > 0.75 else "âŒ"
status_mae = "âœ…" if test_mae < 10 else "âŒ"
status_rmse = "âœ…" if test_rmse < 12 else "âŒ"

print(f"  {status_r2} RÂ² > 0.75:      {test_r2:.4f}")
print(f"  {status_mae} MAE < 10:       {test_mae:.2f}")
print(f"  {status_rmse} RMSE < 12:      {test_rmse:.2f}")

# Distribution erreurs
errors = np.abs(y_test - y_test_pred)
print(f"\nğŸ“ˆ Distribution erreurs absolues (test):")
print(f"  â€¢ < 5 points:  {(errors < 5).sum():,} ({(errors < 5).sum() / len(errors) * 100:.1f}%)")
print(f"  â€¢ < 10 points: {(errors < 10).sum():,} ({(errors < 10).sum() / len(errors) * 100:.1f}%)")
print(f"  â€¢ < 15 points: {(errors < 15).sum():,} ({(errors < 15).sum() / len(errors) * 100:.1f}%)")
print(f"  â€¢ Max error:   {errors.max():.1f} points")

# ============================================================================
# 5. FEATURE IMPORTANCE
# ============================================================================
print("\n\nğŸ” 5. FEATURE IMPORTANCE")
print("-" * 80)

# Feature importance
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("Top 10 features les plus importantes:")
for i, row in feature_importance.head(10).iterrows():
    print(f"  {row['feature']:30s}: {row['importance']:8.1f}")

# ============================================================================
# 6. SAUVEGARDE MODÃˆLE
# ============================================================================
print("\n\nğŸ’¾ 6. SAUVEGARDE MODÃˆLE")
print("-" * 80)

# CrÃ©er dossier models
models_dir = Path("../models/quality_scorer")
models_dir.mkdir(parents=True, exist_ok=True)

# Sauvegarder modÃ¨le avec joblib
model_pkl = models_dir / "scorer.pkl"
joblib.dump(model, model_pkl)
print(f"âœ… ModÃ¨le sauvegardÃ©: {model_pkl}")

# Sauvegarder liste features
features_file = models_dir / "features.txt"
with open(features_file, 'w') as f:
    for feat in feature_cols:
        f.write(f"{feat}\n")
print(f"âœ… Features sauvegardÃ©es: {features_file}")

# Sauvegarder feature importance
importance_file = models_dir / "feature_importance.csv"
feature_importance.to_csv(importance_file, index=False)
print(f"âœ… Feature importance sauvegardÃ©e: {importance_file}")

# Sauvegarder mÃ©triques
metrics = {
    'train_mae': train_mae,
    'train_rmse': train_rmse,
    'train_r2': train_r2,
    'test_mae': test_mae,
    'test_rmse': test_rmse,
    'test_r2': test_r2,
    'n_estimators': model.n_estimators
}

metrics_file = models_dir / "metrics.json"
import json
with open(metrics_file, 'w') as f:
    json.dump(metrics, f, indent=2)
print(f"âœ… MÃ©triques sauvegardÃ©es: {metrics_file}")

# ============================================================================
# 7. TEST PRÃ‰DICTION
# ============================================================================
print("\n\nğŸ§ª 7. TEST PRÃ‰DICTION")
print("-" * 80)

# Prendre quelques exemples
print("Exemples de prÃ©dictions (test set):\n")
print(f"{'POI':40s} {'RÃ©el':>8s} {'PrÃ©dit':>8s} {'Erreur':>8s}")
print("-" * 70)

# SÃ©lectionner exemples variÃ©s
sample_indices = [
    y_test.idxmax(),  # Best
    y_test.idxmin(),  # Worst
    y_test.sample(5, random_state=42).index.tolist()  # Random
]
sample_indices = [sample_indices[0], sample_indices[1]] + sample_indices[2]

for idx in sample_indices[:7]:
    poi_name = df.loc[idx, 'name'] if pd.notna(df.loc[idx, 'name']) else 'N/A'
    real_score = y_test.loc[idx]
    pred_score = y_test_pred[list(y_test.index).index(idx)]
    error = abs(real_score - pred_score)

    poi_name_short = poi_name[:37] + '...' if len(poi_name) > 40 else poi_name
    print(f"{poi_name_short:40s} {real_score:8.1f} {pred_score:8.1f} {error:8.1f}")

# ============================================================================
# RÃ‰SUMÃ‰ FINAL
# ============================================================================
print("\n\n" + "=" * 80)
print("âœ… QUALITY SCORER - ENTRAÃNEMENT TERMINÃ‰")
print("=" * 80)

print(f"\nğŸ¯ Performances finales (test set):")
print(f"  â€¢ RÂ²:   {test_r2:.4f} {'âœ…' if test_r2 > 0.75 else 'âŒ'}")
print(f"  â€¢ MAE:  {test_mae:.2f} points {'âœ…' if test_mae < 10 else 'âŒ'}")
print(f"  â€¢ RMSE: {test_rmse:.2f} points {'âœ…' if test_rmse < 12 else 'âŒ'}")

print(f"\nğŸ“¦ ModÃ¨le sauvegardÃ© dans: {models_dir}/")
print(f"  â€¢ scorer.pkl (modÃ¨le)")
print(f"  â€¢ features.txt (liste features)")
print(f"  â€¢ feature_importance.csv")
print(f"  â€¢ metrics.json")

print(f"\nğŸ“ˆ Prochaine Ã©tape:")
print(f"  â†’ Jours 7-9: Gap Detector (HDBSCAN + Random Forest)")
print(f"  â†’ Objectif: DÃ©tecter opportunitÃ©s business par zone")

print("\n" + "=" * 80)
